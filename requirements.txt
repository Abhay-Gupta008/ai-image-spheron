# Use PyTorch custom index for CUDA compatibility
--extra-index-url https://download.pytorch.org/whl/cu118

# Standard packages (PyPI)
fastapi>=0.95,<1.0
uvicorn==0.23.2
python-multipart==0.0.6

# Hugging Face packages
transformers==4.34.1
diffusers==0.24.0
accelerate==0.25.0
huggingface-hub==0.17.3
tokenizers==0.14.1

# PyTorch packages
torch==2.1.0
torchvision==0.16.0

# Xformers (Only for Linux x86_64)
xformers==0.0.22.post4; sys_platform == "linux" and platform_machine == "x86_64"
